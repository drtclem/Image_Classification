{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification: dogs & cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports up-front\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "### 1.1. Load the data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the training data\n",
    "training_data_path='../data/processed/train'\n",
    "\n",
    "# Get a list of training dog and cat images\n",
    "training_dogs=glob.glob(f'{training_data_path}/dog/dog.*')\n",
    "training_cats=glob.glob(f'{training_data_path}/cat/cat.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,2,figsize=(6, 4))\n",
    "\n",
    "for cat, dog, row in zip(training_cats, training_dogs, axs):\n",
    "    for animal, ax in zip([cat, dog], row):\n",
    "        animal=image.load_img(animal)\n",
    "        animal=image.img_to_array(animal)\n",
    "        animal/=255.0\n",
    "        ax.imshow(animal)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA\n",
    "\n",
    "Let's take a look at a few of our images to get a feel for how image data is structured.\n",
    "\n",
    "### 2.1. Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one of the images as an array and look at it's shape - what do you see, what are the dimensions? Are they what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the three 2D arrays which comprise the image. What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Image dimensions\n",
    "\n",
    "Let's take a look at a random sample of images from the dataset and see what their dimensions are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over a few hundred images and extract their width and heigh, plot both as a histogram. What do you see, does this information matter to us, if so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Image aspect ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the image aspect ratios (i.e. width/height) What do you see, does this information matter to us, if so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the model\n",
    "\n",
    "### 3.1. Prepare images for streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(training_data_path: str, image_dim: int, batch_size: int=16):\n",
    "\n",
    "    training_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        batch_size=batch_size\n",
    "    ).repeat()\n",
    "\n",
    "    validation_dataset=tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        batch_size=batch_size\n",
    "    ).repeat()\n",
    "\n",
    "    AUTOTUNE=tf.data.AUTOTUNE\n",
    "\n",
    "    training_dataset=training_dataset.cache().shuffle(256, reshuffle_each_iteration=True).prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset=training_dataset.cache().shuffle(256, reshuffle_each_iteration=True).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return training_dataset, validation_dataset\n",
    "\n",
    "training_dataset, validation_dataset=make_datasets(training_data_path, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(image_dim, learning_rate):\n",
    "\n",
    "    initializer=tf.keras.initializers.GlorotUniform(seed=315)\n",
    "\n",
    "    model=Sequential([\n",
    "        layers.Input((image_dim, image_dim, 3)),\n",
    "        layers.Rescaling(1./255),\n",
    "        layers.Conv2D(16, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=initializer),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
    "        layers.Dense(1, activation='sigmoid', kernel_initializer=initializer)\n",
    "    ])\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=compile_model(128, 0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "training_results=model.fit(\n",
    "  training_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=10,\n",
    "  steps_per_epoch=5,\n",
    "  validation_steps=5\n",
    ")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at what information 'training_results' contains. Plot the training and validation accuracy (and binary cross-entropy if you like) over the training epoch. Is the model learning? If not, what do you think is wrong?\n",
    "    \n",
    "# Set-up a 1x2 figure for accuracy and binary cross-entropy\n",
    "fig, axs=plt.subplots(1,2, figsize=(8,4))\n",
    "\n",
    "# Add the main title\n",
    "fig.suptitle('CNN training curves', size='large')\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "axs[0].set_title('Accuracy')\n",
    "axs[0].plot(np.array(training_results.history['binary_accuracy']) * 100, label='Training')\n",
    "axs[0].plot(np.array(training_results.history['val_binary_accuracy']) * 100, label='Validation')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Accuracy (%)')\n",
    "axs[0].legend(loc='upper left')\n",
    "\n",
    "# Plot training and validation binary cross-entropy\n",
    "axs[1].set_title('Binary cross-entropy')\n",
    "axs[1].plot(training_results.history['loss'])\n",
    "axs[1].plot(training_results.history['val_loss'])\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Binary cross-entropy')\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try optimizing the learning rate and the batch size using a few values near the default settings. Hint: use a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best values for learning rate and batch size and train the model for longer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model out on the test data - is it as good as you expected, given the training data? Worse? Better? Why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
